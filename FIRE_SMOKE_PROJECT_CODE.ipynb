{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping , ModelCheckpoint\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import models \n",
    "import warnings\n",
    "from keras.models import load_model\n",
    "from torchvision import datasets\n",
    "import torchvision\n",
    "import torch\n",
    "import cv2\n",
    "from torchvision.transforms import transforms\n",
    "import torchvision.models as models\n",
    "from PIL import ImageFile\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "plt.ion()\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting GPU Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.set_logical_device_configuration(\n",
    "    physical_devices[0],\n",
    "    [tf.config.LogicalDeviceConfiguration(memory_limit=4096)])  # Set memory limit to 4GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"GPU is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG = 255\n",
    "IMG_SIZE = [IMG,IMG]\n",
    "numofClasses = 3\n",
    "batchSize = 16\n",
    "EPOCHS = 20\n",
    "PATIENCE = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect the Data from Any Possible Resources\n",
    "Dataset Collection\n",
    "Objective: Obtain a labeled dataset that includes images of fire, smoke, and non-fire scenarios.\n",
    "Sources: The dataset used in this project is the FOREST_FIRE_SMOKE_AND_NON_FIRE_DATASET.\n",
    "Details: The dataset is structured in a directory format, with subfolders representing each of the three classes: fire, smoke, and non fire.\n",
    "Action: Ensure the images are in a readable format (e.g., JPEG, PNG)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = '/mnt/c/Users/sumit/Downloads/Compressed/FOREST_FIRE_SMOKE_AND_NON_FIRE_DATASET/train/'\n",
    "valid_set = '/mnt/c/Users/sumit/Downloads/Compressed/FOREST_FIRE_SMOKE_AND_NON_FIRE_DATASET/test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "Task 2.1: Corrupted Image Removal\n",
    "Objective: Identify and remove corrupted images that do not conform to the JFIF format.\n",
    "Code: The code iterates over the training and testing directories, checking for corrupted images, and deletes them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_skipped = 0\n",
    "for folder_name in ('Neutral','Fire', 'Smoke'):\n",
    "    folder_path = os.path.join(\"/mnt/c/Users/sumit/Downloads/Compressed/FOREST_FIRE_SMOKE_AND_NON_FIRE_DATASET/train\", folder_name)\n",
    "    for fname in os.listdir(folder_path):\n",
    "        fpath = os.path.join(folder_path, fname)\n",
    "        try:\n",
    "            fobj = open(fpath, \"rb\")\n",
    "            is_jfif = b\"JFIF\" in fobj.peek(10)\n",
    "        finally:\n",
    "            fobj.close()\n",
    "\n",
    "        if not is_jfif:\n",
    "            num_skipped += 1\n",
    "            # Delete corrupted image\n",
    "            os.remove(fpath)\n",
    "\n",
    "print(f\"Deleted {num_skipped} images.\")\n",
    "\n",
    "num_skipped = 0\n",
    "for folder_name in ('Neutral','Fire', 'Smoke'):\n",
    "    folder_path = os.path.join(\"/mnt/c/Users/sumit/Downloads/Compressed/FOREST_FIRE_SMOKE_AND_NON_FIRE_DATASET/test\", folder_name)\n",
    "    for fname in os.listdir(folder_path):\n",
    "        fpath = os.path.join(folder_path, fname)\n",
    "        try:\n",
    "            fobj = open(fpath, \"rb\")\n",
    "            is_jfif = b\"JFIF\" in fobj.peek(10)\n",
    "        finally:\n",
    "            fobj.close()\n",
    "\n",
    "        if not is_jfif:\n",
    "            num_skipped += 1\n",
    "            # Delete corrupted image\n",
    "            os.remove(fpath)\n",
    "\n",
    "print(f\"Deleted {num_skipped} images.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection, Training, Predicting, and Assessment\n",
    "Task 6.1: Model Architecture\n",
    "Objective: Select and build a model for classification using CNNs.\n",
    "Details: A simple CNN model is chosen with multiple convolutional layers followed by max-pooling layers. Dropout layers are used to reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Model:\n",
    "model = tf.keras.models.Sequential([\n",
    "\n",
    "    tf.keras.layers.Conv2D(96,(3,3),activation='relu',input_shape = [IMG,IMG,3]),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(256,(3,3),activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(256,(3,3),activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(128,(3,3),activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "\n",
    "    tf.keras.layers.Dense(256,activation='relu'),\n",
    "\n",
    "    tf.keras.layers.Dense(numofClasses, activation='softmax')\n",
    "\n",
    "\n",
    "\n",
    "])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose the Metrics for the Model Evaluation\n",
    "Task 5.1: Model Evaluation Metrics\n",
    "Objective: Choose appropriate metrics for evaluating the model's performance.\n",
    "Metrics Chosen: Accuracy is used as the primary evaluation metric because this is a classification task. Additionally, a confusion matrix can be used for performance analysis (accuracy, precision, recall, F1-score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set desired learning rate\n",
    "learning_rate = 0.0001  # learning rate\n",
    "\n",
    "# Create the Adam optimizer with the specified learning rate\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "# Now compile the model with the optimizer, loss function, and metrics\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',  # Change based on your problem\n",
    "              metrics=['accuracy'])  # or other metrics you want to track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "Objective: Increase the diversity of the training data to avoid overfitting.\n",
    "Code: Use Keras' ImageDataGenerator for augmentation techniques such as rotation, zoom, shift, shear, and horizontal flip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1. /255,\n",
    "                                   rotation_range = 20,\n",
    "                                   width_shift_range = 0.1,\n",
    "                                   height_shift_range = 0.1,\n",
    "                                   shear_range = 0.1,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True,\n",
    "                                   validation_split=0.1\n",
    "                                   )\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. /255,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Resizing and Normalization\n",
    "Objective: Preprocess the images by resizing and normalizing the pixel values to a range of [0,1].\n",
    "Code: Images are resized to 255x255 pixels and normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = train_datagen.flow_from_directory(train_set,\n",
    "                                                 shuffle = True,\n",
    "                                                 target_size = IMG_SIZE,\n",
    "                                                 batch_size=batchSize,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 color_mode='rgb'\n",
    "                                                 )\n",
    "\n",
    "testing_set = train_datagen.flow_from_directory(valid_set,\n",
    "                                                 shuffle = False,\n",
    "                                                 target_size = IMG_SIZE,\n",
    "                                                 batch_size=batchSize,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 color_mode='rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = training_set.class_indices\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepsPerEpochs = int(np.ceil(training_set.samples / batchSize))\n",
    "validationsteps = int(np.ceil(testing_set.samples / batchSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepsPerEpochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_file = \"C:/Users/sumit/Downloads/Compressed/fire_and_smoke_model_final.keras\"\n",
    "bestModel = ModelCheckpoint(best_model_file, monitor='val_accuracy',verbose=1,save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = int(stepsPerEpochs)\n",
    "validation_steps = int(validationsteps)\n",
    "epochs = int(EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "Objective: Train the model using the training dataset.\n",
    "Details: Training is done using the fit method. Early stopping and model checkpointing are used to prevent overfitting and save the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    training_set,\n",
    "    validation_data = testing_set,\n",
    "    epochs = epochs,\n",
    "    steps_per_epoch = stepsPerEpochs,\n",
    "    validation_steps = validationsteps,\n",
    "    verbose = 1,\n",
    "    callbacks = [bestModel]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Assessment\n",
    "Objective: Evaluate the model's performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valResults = model.evaluate(testing_set)\n",
    "print(valResults)\n",
    "print(model.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history[\"accuracy\"]\n",
    "val_acc = history.history[\"val_accuracy\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "actualEpochs = range(len(acc))\n",
    "print(\"Actual Epochs : \"+ str(actualEpochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(actualEpochs,acc , 'r' , label = \"Training accuracy\")\n",
    "plt.plot(actualEpochs, val_acc , 'b' , label = \"Validation accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"fire_and_smoke_model_final.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning/Model Improvement\n",
    " Hyperparameter Optimization Objective: Optimize the model by tuning hyperparameters such as the number of filters, learning rate, dropout rate, etc. Tools Used: Keras Tuner is used for hyperparameter optimization via the RandomSearch method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Model:\n",
    "\n",
    "def build_model(hp):\n",
    "    filter_layer1 = hp.Int(\"filters_layers1\",min_value=32, max_value=256, step=32)\n",
    "    filter_layer2 = hp.Int(\"filters_layers2\",min_value=32, max_value=256, step=32)\n",
    "    filter_layer3 = hp.Int(\"filters_layers3\",min_value=32, max_value=256, step=32)\n",
    "    filter_layer4 = hp.Int(\"filters_layers4\",min_value=32, max_value=256, step=32)\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate',values = [1e-2, 1e-3, 1e-4])\n",
    "    hp_optimizer = tf.keras.optimizers.Adam(learning_rate = hp_learning_rate)\n",
    "    hp_dropout = hp.Choice('drop_out', values = [0.3,0.5])\n",
    "    hp_last_dense_layer = hp.Int('last_dense_layer', min_value = 128, max_value = 786, step = 64)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    model1 = tf.keras.models.Sequential([\n",
    "\n",
    "        tf.keras.layers.Conv2D(filter_layer1,kernel_size = (3,3),activation='relu',input_shape = [IMG,IMG,3]),\n",
    "        tf.keras.layers.MaxPool2D(2,2),\n",
    "\n",
    "        tf.keras.layers.Conv2D(filter_layer2,kernel_size = (3,3),activation='relu'),\n",
    "        tf.keras.layers.MaxPool2D(2,2),\n",
    "\n",
    "        tf.keras.layers.Conv2D(filter_layer3,kernel_size = (3,3),activation='relu'),\n",
    "        tf.keras.layers.MaxPool2D(2,2),\n",
    "\n",
    "        tf.keras.layers.Conv2D(filter_layer4,kernel_size = (3,3),activation='relu'),\n",
    "        tf.keras.layers.MaxPool2D(2,2),\n",
    "\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(hp_dropout),\n",
    "\n",
    "        tf.keras.layers.Dense(hp_last_dense_layer,activation='relu'),\n",
    "\n",
    "        tf.keras.layers.Dense(numofClasses, activation='softmax')\n",
    "\n",
    "\n",
    "\n",
    "    ])\n",
    "\n",
    "    model1.compile(loss='categorical_crossentropy',optimizer=hp_optimizer,metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "    return model1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_file = \"C:/Users/sumit/Downloads/Compressed/fire_and_smoke_model_eran_hyper_peram_1.keras\"\n",
    "# bestModel = ModelCheckpoint(best_model_file, monitor='val_accuracy',verbose=1,save_best_only=True)\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy', patience = PATIENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras Tunner\n",
    "import keras_tuner\n",
    "from keras_tuner import RandomSearch\n",
    "\n",
    "tunner = RandomSearch(\n",
    "    build_model,\n",
    "    objective = 'val_accuracy',\n",
    "    max_trials = 3,\n",
    "    executions_per_trial = 12,\n",
    "    directory = 'C:/Users/sumit/Downloads/Compressed',\n",
    "    project_name = 'FireSmoke_dete_Random_search_HP',\n",
    "    overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training set: {training_set}\")\n",
    "print(f\"Testing set: {testing_set}\")\n",
    "print(f\"EPOCHS: {EPOCHS}\")\n",
    "print(f\"Batch size: {batchSize}\")\n",
    "print(f\"Steps per epoch: {stepsPerEpochs}\")\n",
    "print(f\"Validation steps: {validationsteps}\")\n",
    "\n",
    "# Now, call the search method\n",
    "tunner.search(\n",
    "    training_set,\n",
    "    validation_data=testing_set,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=batchSize,\n",
    "    callbacks=[stop_early],\n",
    "    steps_per_epoch=stepsPerEpochs,\n",
    "    validation_steps=validationsteps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Hyperparameter Selection\n",
    "Objective: Retrieve and use the best hyperparameters found through the tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best perameter\n",
    "best_hp = tunner.get_best_hyperparameters()[0].values\n",
    "print(\"==========================\")\n",
    "print(\"Best model parameters :\")\n",
    "print(best_hp)\n",
    "print(\"==========================\")\n",
    "print(\"  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model Selection\n",
    "Objective: Retrieve and use the best model found through the tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best Model\n",
    "model = tunner.get_best_models(num_models = 1)[0]\n",
    "print(\"==========================\")\n",
    "print(\"Best model :\")\n",
    "print(model.summary())\n",
    "print(\"==========================\")\n",
    "print(\"  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for better accuracy the model I have used transfer learning technique. Architecture used here is ResNet.\n",
    "I have achieved validation accuracy of 93% using ResNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_workers = 0\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(size=(256,256)),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = '/mnt/c/Users/sumit/Downloads/Compressed/FOREST_FIRE_SMOKE_AND_NON_FIRE_DATASET/train'\n",
    "valid_set = '/mnt/c/Users/sumit/Downloads/Compressed/FOREST_FIRE_SMOKE_AND_NON_FIRE_DATASET/test'\n",
    "\n",
    "\n",
    "train_data = datasets.ImageFolder(train_set, transform=transform)\n",
    "valid_data = datasets.ImageFolder(valid_set, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "\n",
    "loaders = {\n",
    "    'train': train_loader,\n",
    "    'valid': valid_loader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Neutral','Fire', 'Smoke']\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "    \n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.fc = torch.nn.Sequential(torch.nn.Linear(2048,128),\n",
    "                                      torch.nn.ReLU(),\n",
    "                                       torch.nn.Linear(128,3),\n",
    "                                       torch.nn.Softmax()\n",
    "                                      )\n",
    "\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "if use_cuda:\n",
    "    model_transfer = model.cuda()\n",
    "    \n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_transfer.fc.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "\n",
    "train_accuracy_list = []\n",
    "train_loss_list = []\n",
    "valid_accuracy_list = []\n",
    "valid_loss_list = []\n",
    "\n",
    "def train(n_epochs, loader, model, optimizer, criterion, use_cuda, save_path):\n",
    "    \n",
    "    valid_loss_min = np.inf\n",
    "       \n",
    "    for epoch in range(1, (n_epochs+1)):\n",
    "        \n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        valid_acc = 0.0\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "            \n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            _, preds = torch.max(output, 1)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_acc = train_acc + torch.sum(preds == target.data)\n",
    "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "            \n",
    "            model.eval()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            output = model(data)\n",
    "            _, preds = torch.max(output, 1)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            valid_acc = valid_acc + torch.sum(preds == target.data)\n",
    "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
    "            \n",
    "        train_loss = train_loss/len(loaders['train'].dataset)\n",
    "        valid_loss = valid_loss/len(loaders['valid'].dataset)\n",
    "        train_acc = train_acc/len(loaders['train'].dataset)\n",
    "        valid_acc = valid_acc/len(loaders['valid'].dataset)\n",
    "        \n",
    "        train_accuracy_list.append(train_acc)\n",
    "        train_loss_list.append(train_loss)\n",
    "        valid_accuracy_list.append(valid_acc)\n",
    "        valid_loss_list.append(valid_loss)\n",
    "        \n",
    "        print('Epoch: {} \\tTraining Acc: {:6f} \\tTraining Loss: {:6f} \\tValidation Acc: {:6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch,\n",
    "            train_acc,\n",
    "            train_loss,\n",
    "            valid_acc,\n",
    "            valid_loss\n",
    "            ))\n",
    "\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss))\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            valid_loss_min = valid_loss  \n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train(n_epochs, loaders, model, optimizer, criterion, use_cuda, '/mnt/c/Users/sumit/Downloads/Compressed/model_final.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(train_loss_list, label=\"train_loss\")\n",
    "plt.title(\"Train-Loss\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"lower left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(train_accuracy_list, label=\"train_acc\")\n",
    "plt.plot(valid_accuracy_list, label=\"valid_acc\")\n",
    "\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=\"lower left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment Plan\n",
    "Model Saving Objective: Save the best-performing model after training and hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, '/mnt/c/Users/sumit/Downloads/Compressed/models/model_final.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment and Inference\n",
    "Objective: The model can be deployed in real-world applications, such as monitoring forest fires. The model will be able to classify images from surveillance cameras in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('/mnt/c/Users/sumit/Downloads/Compressed/Fire-Smoke-Detection-master/Fire-Smoke-Detection-master/trained-models/model_final.pth')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integration into a System\n",
    "Objective: The model can be integrated into a larger system for real-time detection of fire, smoke, or non-fire. Action: Use a web or mobile app to send images to the model and retrieve classification results in real-time.\n",
    "\n",
    "Summary of Tasks and Activities Collect the data: Download or gather the relevant dataset of images (fire, smoke, non-fire). Data preprocessing: Clean the data, remove corrupted images, and augment the dataset. Feature engineering: Extract features through CNN layers (no explicit manual feature extraction). Train/Test Split: Split the data into training and validation sets. Metrics for evaluation: Accuracy is selected as the evaluation metric. Model selection, training, and assessment: Build and train a CNN, then evaluate it on the test set. Hyperparameter tuning: Tune the model’s hyperparameters using Keras Tuner. Model deployment plan: Save the model and create a plan for real-time deployment and inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Prediction\n",
    "Objective: Use the trained model to make predictions on new (test) images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = class_names = ['Fire', 'Neutral', 'Smoke']\n",
    "\n",
    "def predict(image):\n",
    "    prediction_transform = transforms.Compose([transforms.Resize(size=(224, 224)),\n",
    "                                     transforms.ToTensor(), \n",
    "                                     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "    image = prediction_transform(image)[:3,:,:].unsqueeze(0)\n",
    "    image = image.cuda()\n",
    "\n",
    "    pred = model(image)\n",
    "    idx = torch.argmax(pred)\n",
    "    prob = pred[0][idx].item()*100\n",
    "    \n",
    "    return class_names[idx], prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('/mnt/c/Users/sumit/Downloads/Compressed/FIRE-SMOKE-DATASET_2/FIRE-SMOKE-DATASET/Train/Neutral/image_41.jpg')\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "prediction, prob = predict(img)\n",
    "print(prediction, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('/mnt/c/Users/sumit/Downloads/Compressed/FOREST_FIRE_SMOKE_AND_NON_FIRE_DATASET/test/fire/Fire (45).jpeg')\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "prediction, prob = predict(img)\n",
    "print(prediction, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('/mnt/c/Users/sumit/Downloads/Compressed/FOREST_FIRE_SMOKE_AND_NON_FIRE_DATASET/test/Smoke/Smoke (945).jpg')\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "prediction, prob = predict(img)\n",
    "print(prediction, prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('/mnt/c/Users/sumit/Downloads/Compressed/FOREST_FIRE_SMOKE_AND_NON_FIRE_DATASET/test/Smoke/videoplayback.mp4')\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, image = cap.read()\n",
    "    draw = image.copy()\n",
    "    draw = cv2.resize(draw,(640,480))\n",
    "    \n",
    "    draw = transforms.ToPILImage()(draw)\n",
    "    prediction, prob = predict(draw)\n",
    "    \n",
    "    if prediction == 'Neutral':\n",
    "        color = (0, 255, 0)\n",
    "    else:\n",
    "        color = (0, 0, 255)\n",
    "    cv2.putText(image, (prediction+' '+str(prob)), (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "    \n",
    "\n",
    "    cv2.imshow('framename', image)\n",
    "        \n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
